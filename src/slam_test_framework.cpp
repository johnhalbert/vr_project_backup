#include "include/slam_test_framework.hpp"
#include "include/tpu_feature_extractor.hpp"
#include "include/multi_camera_rig.hpp"
#include "include/vr_motion_model.hpp"
#include "include/bno085_interface.hpp"
#include "include/zero_copy_frame_provider.hpp"

#include <iostream>
#include <fstream>
#include <iomanip>
#include <algorithm>
#include <opencv2/imgcodecs.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/imgproc.hpp>

namespace ORB_SLAM3
{

//------------------------------------------------------------------------------
// TestCase Implementation
//------------------------------------------------------------------------------

TestCase::TestCase(const std::string& name, const std::string& description)
    : name_(name), description_(description)
{
}

TestCase::~TestCase()
{
}

TestResult TestCase::Run()
{
    TestResult result;
    result.name = name_;
    result.description = description_;
    result.success = false;
    
    // Measure execution time
    auto start_time = std::chrono::high_resolution_clock::now();
    
    try {
        // Execute the test
        Execute(result);
    } catch (const std::exception& e) {
        SetFailure(result, std::string("Exception: ") + e.what());
    } catch (...) {
        SetFailure(result, "Unknown exception");
    }
    
    // Calculate execution time
    auto end_time = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
    result.execution_time_ms = duration.count();
    
    return result;
}

std::string TestCase::GetName() const
{
    return name_;
}

std::string TestCase::GetDescription() const
{
    return description_;
}

void TestCase::Log(TestResult& result, const std::string& message)
{
    result.logs.push_back(message);
    std::cout << "[" << name_ << "] " << message << std::endl;
}

void TestCase::SetSuccess(TestResult& result, const std::string& message)
{
    result.success = true;
    result.message = message;
    Log(result, "SUCCESS: " + message);
}

void TestCase::SetFailure(TestResult& result, const std::string& message)
{
    result.success = false;
    result.message = message;
    Log(result, "FAILURE: " + message);
}

//------------------------------------------------------------------------------
// TestSuite Implementation
//------------------------------------------------------------------------------

TestSuite::TestSuite(const std::string& name)
    : name_(name)
{
}

TestSuite::~TestSuite()
{
}

void TestSuite::AddTest(std::shared_ptr<TestCase> test)
{
    tests_.push_back(test);
}

std::vector<TestResult> TestSuite::RunAll()
{
    std::vector<TestResult> results;
    
    std::cout << "Running test suite: " << name_ << std::endl;
    std::cout << "----------------------------------------" << std::endl;
    
    for (const auto& test : tests_) {
        std::cout << "Running test: " << test->GetName() << std::endl;
        TestResult result = test->Run();
        results.push_back(result);
        std::cout << (result.success ? "PASSED" : "FAILED") << " (" 
                  << result.execution_time_ms << " ms)" << std::endl;
        std::cout << "----------------------------------------" << std::endl;
    }
    
    return results;
}

TestResult TestSuite::RunTest(const std::string& name)
{
    TestResult empty_result;
    empty_result.name = "Not Found";
    empty_result.success = false;
    empty_result.message = "Test not found: " + name;
    
    for (const auto& test : tests_) {
        if (test->GetName() == name) {
            std::cout << "Running test: " << test->GetName() << std::endl;
            TestResult result = test->Run();
            std::cout << (result.success ? "PASSED" : "FAILED") << " (" 
                      << result.execution_time_ms << " ms)" << std::endl;
            return result;
        }
    }
    
    return empty_result;
}

std::string TestSuite::GetName() const
{
    return name_;
}

std::vector<std::shared_ptr<TestCase>> TestSuite::GetTests() const
{
    return tests_;
}

//------------------------------------------------------------------------------
// TestRunner Implementation
//------------------------------------------------------------------------------

TestRunner::TestRunner()
{
}

TestRunner::~TestRunner()
{
}

void TestRunner::AddSuite(std::shared_ptr<TestSuite> suite)
{
    suites_.push_back(suite);
}

std::vector<TestResult> TestRunner::RunAll()
{
    std::vector<TestResult> all_results;
    
    std::cout << "Running all test suites" << std::endl;
    std::cout << "========================================" << std::endl;
    
    for (const auto& suite : suites_) {
        std::vector<TestResult> suite_results = suite->RunAll();
        all_results.insert(all_results.end(), suite_results.begin(), suite_results.end());
    }
    
    std::cout << "========================================" << std::endl;
    std::cout << "All tests completed" << std::endl;
    
    return all_results;
}

std::vector<TestResult> TestRunner::RunSuite(const std::string& suite_name)
{
    for (const auto& suite : suites_) {
        if (suite->GetName() == suite_name) {
            return suite->RunAll();
        }
    }
    
    std::vector<TestResult> empty_results;
    std::cout << "Test suite not found: " << suite_name << std::endl;
    return empty_results;
}

TestResult TestRunner::RunTest(const std::string& suite_name, const std::string& test_name)
{
    for (const auto& suite : suites_) {
        if (suite->GetName() == suite_name) {
            return suite->RunTest(test_name);
        }
    }
    
    TestResult empty_result;
    empty_result.name = "Not Found";
    empty_result.success = false;
    empty_result.message = "Test suite not found: " + suite_name;
    return empty_result;
}

void TestRunner::GenerateReport(const std::vector<TestResult>& results, const std::string& output_file)
{
    // Count passed and failed tests
    int passed = 0;
    int failed = 0;
    double total_time = 0.0;
    
    for (const auto& result : results) {
        if (result.success) {
            passed++;
        } else {
            failed++;
        }
        total_time += result.execution_time_ms;
    }
    
    // Generate report
    std::stringstream report;
    report << "SLAM Test Report" << std::endl;
    report << "================" << std::endl;
    report << "Total tests: " << results.size() << std::endl;
    report << "Passed: " << passed << std::endl;
    report << "Failed: " << failed << std::endl;
    report << "Total time: " << total_time << " ms" << std::endl;
    report << std::endl;
    
    report << "Test Results" << std::endl;
    report << "------------" << std::endl;
    
    for (const auto& result : results) {
        report << result.name << ": " << (result.success ? "PASSED" : "FAILED") << std::endl;
        report << "  Description: " << result.description << std::endl;
        report << "  Message: " << result.message << std::endl;
        report << "  Time: " << result.execution_time_ms << " ms" << std::endl;
        
        if (!result.logs.empty()) {
            report << "  Logs:" << std::endl;
            for (const auto& log : result.logs) {
                report << "    " << log << std::endl;
            }
        }
        
        report << std::endl;
    }
    
    // Output report
    if (output_file.empty()) {
        std::cout << report.str();
    } else {
        std::ofstream file(output_file);
        if (file.is_open()) {
            file << report.str();
            file.close();
            std::cout << "Report written to " << output_file << std::endl;
        } else {
            std::cerr << "Failed to write report to " << output_file << std::endl;
            std::cout << report.str();
        }
    }
}

//------------------------------------------------------------------------------
// TPUFeatureExtractorTest Implementation
//------------------------------------------------------------------------------

TPUFeatureExtractorTest::TPUFeatureExtractorTest(const std::string& model_path, const std::string& test_image_path)
    : TestCase("TPUFeatureExtractorTest", "Test TPU Feature Extractor functionality"),
      model_path_(model_path),
      test_image_path_(test_image_path)
{
}

TPUFeatureExtractorTest::~TPUFeatureExtractorTest()
{
}

void TPUFeatureExtractorTest::Execute(TestResult& result)
{
    // Load test image
    cv::Mat image = cv::imread(test_image_path_, cv::IMREAD_GRAYSCALE);
    if (image.empty()) {
        SetFailure(result, "Failed to load test image: " + test_image_path_);
        return;
    }
    
    Log(result, "Loaded test image: " + test_image_path_ + " (" + 
        std::to_string(image.cols) + "x" + std::to_string(image.rows) + ")");
    
    try {
        // Create TPU Feature Extractor
        Log(result, "Creating TPU Feature Extractor with model: " + model_path_);
        TPUFeatureExtractor extractor(model_path_, "", 1000, 1.2f, 8);
        
        // Extract features
        Log(result, "Extracting features from test image");
        std::vector<cv::KeyPoint> keypoints;
        cv::Mat descriptors;
        
        extractor(image, cv::Mat(), keypoints, descriptors);
        
        // Check results
        Log(result, "Extracted " + std::to_string(keypoints.size()) + " keypoints");
        Log(result, "Descriptor dimensions: " + std::to_string(descriptors.rows) + "x" + 
            std::to_string(descriptors.cols));
        
        if (keypoints.empty()) {
            SetFailure(result, "No keypoints detected");
            return;
        }
        
        if (descriptors.empty()) {
            SetFailure(result, "No descriptors generated");
            return;
        }
        
        // Visualize keypoints (optional)
        cv::Mat keypoint_image;
        cv::drawKeypoints(image, keypoints, keypoint_image, cv::Scalar::all(-1), 
                         cv::DrawMatchesFlags::DRAW_RICH_KEYPOINTS);
        cv::imwrite("/tmp/tpu_keypoints.jpg", keypoint_image);
        Log(result, "Keypoint visualization saved to /tmp/tpu_keypoints.jpg");
        
        SetSuccess(result, "TPU Feature Extractor test passed");
    } catch (const std::exception& e) {
        SetFailure(result, std::string("Exception during feature extraction: ") + e.what());
    }
}

//------------------------------------------------------------------------------
// MultiCameraRigTest Implementation
//------------------------------------------------------------------------------

MultiCameraRigTest::MultiCameraRigTest(const std::string& calibration_path, const std::string& test_images_path)
    : TestCase("MultiCameraRigTest", "Test Multi-Camera Rig functionality"),
      calibration_path_(calibration_path),
      test_images_path_(test_images_path)
{
}

MultiCameraRigTest::~MultiCameraRigTest()
{
}

void MultiCameraRigTest::Execute(TestResult& result)
{
    try {
        // Create Multi-Camera Rig
        Log(result, "Creating Multi-Camera Rig");
        MultiCameraRig rig;
        
        // Load calibration if provided
        if (!calibration_path_.empty()) {
            Log(result, "Loading calibration from: " + calibration_path_);
            if (!rig.LoadCalibration(calibration_path_)) {
                SetFailure(result, "Failed to load calibration");
                return;
            }
        } else {
            // Create a simple test rig with two cameras
            Log(result, "Creating test rig with two cameras");
            
            MultiCameraRig::CameraInfo camera1;
            camera1.id = 0;
            camera1.K = (cv::Mat_<float>(3, 3) << 
                         500.0f, 0.0f, 320.0f,
                         0.0f, 500.0f, 240.0f,
                         0.0f, 0.0f, 1.0f);
            camera1.distCoef = (cv::Mat_<float>(1, 5) << 0.0f, 0.0f, 0.0f, 0.0f, 0.0f);
            camera1.T_ref_cam = cv::Mat::eye(4, 4, CV_32F);
            camera1.fps = 30.0f;
            camera1.width = 640;
            camera1.height = 480;
            camera1.model = "pinhole";
            camera1.fov_horizontal = 90.0f;
            camera1.fov_vertical = 60.0f;
            
            MultiCameraRig::CameraInfo camera2;
            camera2.id = 1;
            camera2.K = (cv::Mat_<float>(3, 3) << 
                         500.0f, 0.0f, 320.0f,
                         0.0f, 500.0f, 240.0f,
                         0.0f, 0.0f, 1.0f);
            camera2.distCoef = (cv::Mat_<float>(1, 5) << 0.0f, 0.0f, 0.0f, 0.0f, 0.0f);
            camera2.T_ref_cam = (cv::Mat_<float>(4, 4) << 
                                1.0f, 0.0f, 0.0f, 0.1f,
                                0.0f, 1.0f, 0.0f, 0.0f,
                                0.0f, 0.0f, 1.0f, 0.0f,
                                0.0f, 0.0f, 0.0f, 1.0f);
            camera2.fps = 30.0f;
            camera2.width = 640;
            camera2.height = 480;
            camera2.model = "pinhole";
            camera2.fov_horizontal = 90.0f;
            camera2.fov_vertical = 60.0f;
            
            rig.AddCamera(camera1);
            rig.AddCamera(camera2);
            rig.SetReferenceCameraId(0);
        }
        
        // Load test images if provided
        std::vector<cv::Mat> images;
        if (!test_images_path_.empty()) {
            Log(result, "Loading test images from: " + test_images_path_);
            
            // Load images for each camera
            std::vector<std::string> camera_dirs;
            camera_dirs.push_back(test_images_path_ + "/cam0");
            camera_dirs.push_back(test_images_path_ + "/cam1");
            
            for (const auto& dir : camera_dirs) {
                cv::Mat image = cv::imread(dir + "/000000.jpg");
                if (image.empty()) {
                    Log(result, "Warning: Failed to load image from " + dir);
                    image = cv::Mat::zeros(480, 640, CV_8UC3);
                }
                images.push_back(image);
            }
        } else {
            // Create test images
            Log(result, "Creating test images");
            cv::Mat image1 = cv::Mat::zeros(480, 640, CV_8UC3);
            cv::circle(image1, cv::Point(320, 240), 100, cv::Scalar(0, 0, 255), -1);
            
            cv::Mat image2 = cv::Mat::zeros(480, 640, CV_8UC3);
            cv::circle(image2, cv::Point(320, 240), 100, cv::Scalar(0, 255, 0), -1);
            
            images.push_back(image1);
            images.push_back(image2);
        }
        
        // Test spherical projection
        Log(result, "Testing spherical projection");
        cv::Mat panorama = rig.ProjectToSpherical(images);
        
        if (panorama.empty()) {
            SetFailure(result, "Failed to create spherical panorama");
            return;
        }
        
        cv::imwrite("/tmp/panorama.jpg", panorama);
        Log(result, "Panorama saved to /tmp/panorama.jpg");
        
        // Test point projection
        Log(result, "Testing point projection");
        std::vector<cv::Point2f> points = {
            cv::Point2f(320, 240),
            cv::Point2f(100, 100),
            cv::Point2f(500, 400)
        };
        
        std::vector<cv::Point3f> sphere_points = rig.ProjectPointsToSphere(points, 0);
        std::vector<cv::Point2f> reprojected_points = rig.ProjectSphericalPointsToCamera(sphere_points, 1);
        
        Log(result, "Projected " + std::to_string(points.size()) + " points to sphere and back");
        
        // Test camera selection
        Log(result, "Testing camera selection");
        for (const auto& point : sphere_points) {
            int best_camera = rig.FindBestCameraForPoint(point);
            Log(result, "Best camera for point (" + std::to_string(point.x) + ", " + 
                std::to_string(point.y) + ", " + std::to_string(point.z) + "): " + 
                std::to_string(best_camera));
        }
        
        // Test transform
        Log(result, "Testing camera transforms");
        cv::Point3f test_point(1.0f, 0.0f, 2.0f);
        cv::Point3f transformed_point = rig.TransformPoint(test_point, 0, 1);
        Log(result, "Transformed point: (" + std::to_string(transformed_point.x) + ", " + 
            std::to_string(transformed_point.y) + ", " + std::to_string(transformed_point.z) + ")");
        
        // Save calibration
        Log(result, "Testing calibration save/load");
        if (rig.SaveCalibration("/tmp/rig_calibration.json")) {
            Log(result, "Calibration saved to /tmp/rig_calibration.json");
            
            // Create a new rig and load the calibration
            MultiCameraRig rig2;
            if (rig2.LoadCalibration("/tmp/rig_calibration.json")) {
                Log(result, "Successfully loaded calibration in new rig instance");
            } else {
                SetFailure(result, "Failed to load saved calibration");
                return;
            }
        } else {
            SetFailure(result, "Failed to save calibration");
            return;
        }
        
        SetSuccess(result, "Multi-Camera Rig test passed");
    } catch (const std::exception& e) {
        SetFailure(result, std::string("Exception: ") + e.what());
    }
}

//------------------------------------------------------------------------------
// VRMotionModelTest Implementation
//------------------------------------------------------------------------------

VRMotionModelTest::VRMotionModelTest(const std::string& trajectory_path)
    : TestCase("VRMotionModelTest", "Test VR Motion Model functionality"),
      trajectory_path_(trajectory_path)
{
}

VRMotionModelTest::~VRMotionModelTest()
{
}

void VRMotionModelTest::Execute(TestResult& result)
{
    try {
        // Create VR Motion Model
        Log(result, "Creating VR Motion Model");
        VRMotionModel model;
        
        // Load trajectory if provided
        std::vector<Sophus::SE3f> trajectory;
        std::vector<double> timestamps;
        
        if (!trajectory_path_.empty()) {
            Log(result, "Loading trajectory from: " + trajectory_path_);
            
            std::ifstream file(trajectory_path_);
            if (!file.is_open()) {
                SetFailure(result, "Failed to open trajectory file: " + trajectory_path_);
                return;
            }
            
            std::string line;
            while (std::getline(file, line)) {
                std::stringstream ss(line);
                double timestamp;
                float tx, ty, tz, qx, qy, qz, qw;
                
                ss >> timestamp >> tx >> ty >> tz >> qx >> qy >> qz >> qw;
                
                if (ss.fail()) {
                    continue;
                }
                
                Eigen::Quaternionf q(qw, qx, qy, qz);
                Eigen::Vector3f t(tx, ty, tz);
                
                trajectory.push_back(Sophus::SE3f(q, t));
                timestamps.push_back(timestamp);
            }
            
            if (trajectory.empty()) {
                SetFailure(result, "Failed to load trajectory or trajectory is empty");
                return;
            }
            
            Log(result, "Loaded " + std::to_string(trajectory.size()) + " poses from trajectory");
        } else {
            // Create a synthetic trajectory
            Log(result, "Creating synthetic trajectory");
            
            double t = 0.0;
            for (int i = 0; i < 100; ++i) {
                // Create a circular motion with some up/down movement
                float angle = i * 0.1f;
                float x = std::cos(angle) * 2.0f;
                float y = std::sin(angle) * 2.0f;
                float z = std::sin(angle * 0.5f) * 0.5f;
                
                // Create a rotation that follows the direction of motion
                Eigen::Vector3f direction(std::cos(angle + M_PI_2), std::sin(angle + M_PI_2), 0);
                Eigen::Vector3f up(0, 0, 1);
                Eigen::Vector3f right = up.cross(direction).normalized();
                
                Eigen::Matrix3f rotation;
                rotation.col(0) = right;
                rotation.col(1) = direction;
                rotation.col(2) = up;
                
                Eigen::Quaternionf q(rotation);
                Eigen::Vector3f translation(x, y, z);
                
                trajectory.push_back(Sophus::SE3f(q, translation));
                timestamps.push_back(t);
                
                t += 0.033; // ~30Hz
            }
        }
        
        // Test prediction
        Log(result, "Testing motion prediction");
        
        // Add poses to the model
        for (size_t i = 0; i < trajectory.size(); ++i) {
            model.AddPose(trajectory[i], timestamps[i]);
            
            // Add some synthetic IMU data
            if (i > 0) {
                double dt = timestamps[i] - timestamps[i-1];
                if (dt > 0) {
                    // Calculate angular velocity from pose difference
                    Eigen::Quaternionf q1 = trajectory[i-1].unit_quaternion();
                    Eigen::Quaternionf q2 = trajectory[i].unit_quaternion();
                    Eigen::Quaternionf q_diff = q2 * q1.inverse();
                    Eigen::AngleAxisf angle_axis(q_diff);
                    Eigen::Vector3f angular_velocity = angle_axis.axis() * angle_axis.angle() / dt;
                    
                    // Calculate linear acceleration from position difference
                    Eigen::Vector3f p1 = trajectory[i-1].translation();
                    Eigen::Vector3f p2 = trajectory[i].translation();
                    Eigen::Vector3f v1 = (i > 1) ? 
                        (trajectory[i-1].translation() - trajectory[i-2].translation()) / 
                        (timestamps[i-1] - timestamps[i-2]) : 
                        Eigen::Vector3f::Zero();
                    Eigen::Vector3f v2 = (p2 - p1) / dt;
                    Eigen::Vector3f acceleration = (v2 - v1) / dt;
                    
                    // Add gravity
                    Eigen::Vector3f gravity(0, 0, 9.81);
                    Eigen::Vector3f accel_with_gravity = acceleration + gravity;
                    
                    // Transform to body frame
                    Eigen::Vector3f accel_body = q2.inverse() * accel_with_gravity;
                    
                    model.AddIMU(angular_velocity, accel_body, timestamps[i]);
                }
            }
            
            // Test prediction at various points
            if (i >= 10 && i % 10 == 0) {
                // Predict 16ms ahead (typical VR frame time)
                Sophus::SE3f predicted_pose = model.PredictPose(16.0);
                
                // If we have a future pose, compare with it
                if (i + 1 < trajectory.size()) {
                    double future_time = timestamps[i] + 0.016;
                    size_t future_idx = i + 1;
                    while (future_idx < trajectory.size() && timestamps[future_idx] < future_time) {
                        future_idx++;
                    }
                    
                    if (future_idx < trajectory.size()) {
                        // Interpolate between poses to get ground truth
                        double alpha = (future_time - timestamps[future_idx-1]) / 
                                      (timestamps[future_idx] - timestamps[future_idx-1]);
                        
                        Eigen::Vector3f t1 = trajectory[future_idx-1].translation();
                        Eigen::Vector3f t2 = trajectory[future_idx].translation();
                        Eigen::Vector3f t_interp = t1 * (1 - alpha) + t2 * alpha;
                        
                        Eigen::Quaternionf q1 = trajectory[future_idx-1].unit_quaternion();
                        Eigen::Quaternionf q2 = trajectory[future_idx].unit_quaternion();
                        Eigen::Quaternionf q_interp = q1.slerp(alpha, q2);
                        
                        Sophus::SE3f ground_truth(q_interp, t_interp);
                        
                        // Calculate error
                        Eigen::Vector3f translation_error = predicted_pose.translation() - ground_truth.translation();
                        float translation_error_norm = translation_error.norm();
                        
                        Eigen::Quaternionf q_pred = predicted_pose.unit_quaternion();
                        Eigen::Quaternionf q_gt = ground_truth.unit_quaternion();
                        Eigen::Quaternionf q_error = q_pred * q_gt.inverse();
                        Eigen::AngleAxisf angle_axis_error(q_error);
                        float rotation_error = angle_axis_error.angle();
                        
                        Log(result, "Prediction at t=" + std::to_string(timestamps[i]) + 
                            ", Translation error: " + std::to_string(translation_error_norm) + 
                            "m, Rotation error: " + std::to_string(rotation_error * 180.0f / M_PI) + "Â°");
                        
                        // Check if error is within acceptable limits
                        if (translation_error_norm > 0.1f) {
                            Log(result, "Warning: Large translation prediction error");
                        }
                        
                        if (rotation_error > 0.1f) {
                            Log(result, "Warning: Large rotation prediction error");
                        }
                    }
                }
                
                // Test state estimation
                VRMotionModel::HeadsetState state = model.EstimateHeadsetState();
                Eigen::Vector3f linear_velocity = model.EstimateLinearVelocity();
                Eigen::Vector3f angular_velocity = model.EstimateAngularVelocity();
                
                std::string state_str;
                switch (state) {
                    case VRMotionModel::HeadsetState::STATIONARY:
                        state_str = "STATIONARY";
                        break;
                    case VRMotionModel::HeadsetState::SLOW_MOVEMENT:
                        state_str = "SLOW_MOVEMENT";
                        break;
                    case VRMotionModel::HeadsetState::FAST_MOVEMENT:
                        state_str = "FAST_MOVEMENT";
                        break;
                    case VRMotionModel::HeadsetState::ROTATION_ONLY:
                        state_str = "ROTATION_ONLY";
                        break;
                }
                
                Log(result, "State at t=" + std::to_string(timestamps[i]) + ": " + state_str);
                Log(result, "Linear velocity: (" + std::to_string(linear_velocity.x()) + ", " + 
                    std::to_string(linear_velocity.y()) + ", " + std::to_string(linear_velocity.z()) + ") m/s");
                Log(result, "Angular velocity: (" + std::to_string(angular_velocity.x()) + ", " + 
                    std::to_string(angular_velocity.y()) + ", " + std::to_string(angular_velocity.z()) + ") rad/s");
            }
        }
        
        // Test latency compensation
        Log(result, "Testing latency compensation");
        model.SetLatencyCompensation(10.0);
        double latency = model.GetLatencyCompensation();
        Log(result, "Latency compensation set to " + std::to_string(latency) + " ms");
        
        // Test reset
        Log(result, "Testing reset");
        model.Reset();
        
        SetSuccess(result, "VR Motion Model test passed");
    } catch (const std::exception& e) {
        SetFailure(result, std::string("Exception: ") + e.what());
    }
}

//------------------------------------------------------------------------------
// BNO085InterfaceTest Implementation
//------------------------------------------------------------------------------

BNO085InterfaceTest::BNO085InterfaceTest(const std::string& imu_data_path)
    : TestCase("BNO085InterfaceTest", "Test BNO085 Interface functionality"),
      imu_data_path_(imu_data_path)
{
}

BNO085InterfaceTest::~BNO085InterfaceTest()
{
}

void BNO085InterfaceTest::Execute(TestResult& result)
{
    // This is a placeholder implementation since BNO085Interface is not fully implemented yet
    Log(result, "BNO085 Interface test not fully implemented yet");
    
    // Check if IMU data file exists
    if (!imu_data_path_.empty()) {
        std::ifstream file(imu_data_path_);
        if (file.is_open()) {
            Log(result, "IMU data file exists: " + imu_data_path_);
            file.close();
        } else {
            Log(result, "IMU data file does not exist: " + imu_data_path_);
        }
    }
    
    // For now, just mark as success
    SetSuccess(result, "BNO085 Interface test placeholder passed");
}

//------------------------------------------------------------------------------
// ZeroCopyFrameProviderTest Implementation
//------------------------------------------------------------------------------

ZeroCopyFrameProviderTest::ZeroCopyFrameProviderTest(const std::string& video_path)
    : TestCase("ZeroCopyFrameProviderTest", "Test Zero Copy Frame Provider functionality"),
      video_path_(video_path)
{
}

ZeroCopyFrameProviderTest::~ZeroCopyFrameProviderTest()
{
}

void ZeroCopyFrameProviderTest::Execute(TestResult& result)
{
    // This is a placeholder implementation since ZeroCopyFrameProvider is not fully implemented yet
    Log(result, "Zero Copy Frame Provider test not fully implemented yet");
    
    // Check if video file exists
    if (!video_path_.empty()) {
        std::ifstream file(video_path_);
        if (file.is_open()) {
            Log(result, "Video file exists: " + video_path_);
            file.close();
        } else {
            Log(result, "Video file does not exist: " + video_path_);
        }
    }
    
    // For now, just mark as success
    SetSuccess(result, "Zero Copy Frame Provider test placeholder passed");
}

//------------------------------------------------------------------------------
// SLAMIntegrationTest Implementation
//------------------------------------------------------------------------------

SLAMIntegrationTest::SLAMIntegrationTest(const std::string& config_path, const std::string& dataset_path)
    : TestCase("SLAMIntegrationTest", "Test full SLAM system integration"),
      config_path_(config_path),
      dataset_path_(dataset_path)
{
}

SLAMIntegrationTest::~SLAMIntegrationTest()
{
}

void SLAMIntegrationTest::Execute(TestResult& result)
{
    // This is a placeholder implementation for the full SLAM integration test
    Log(result, "SLAM Integration test not fully implemented yet");
    
    // Check if config file exists
    if (!config_path_.empty()) {
        std::ifstream file(config_path_);
        if (file.is_open()) {
            Log(result, "Config file exists: " + config_path_);
            file.close();
        } else {
            Log(result, "Config file does not exist: " + config_path_);
        }
    }
    
    // Check if dataset exists
    if (!dataset_path_.empty()) {
        std::ifstream file(dataset_path_ + "/info.txt");
        if (file.is_open()) {
            Log(result, "Dataset exists: " + dataset_path_);
            file.close();
        } else {
            Log(result, "Dataset does not exist or is incomplete: " + dataset_path_);
        }
    }
    
    // For now, just mark as success
    SetSuccess(result, "SLAM Integration test placeholder passed");
}

//------------------------------------------------------------------------------
// PerformanceTest Implementation
//------------------------------------------------------------------------------

PerformanceTest::PerformanceTest(const std::string& component_name, const std::string& test_data_path, int iterations)
    : TestCase("PerformanceTest_" + component_name, "Performance test for " + component_name),
      component_name_(component_name),
      test_data_path_(test_data_path),
      iterations_(iterations)
{
}

PerformanceTest::~PerformanceTest()
{
}

void PerformanceTest::Execute(TestResult& result)
{
    Log(result, "Running performance test for " + component_name_);
    Log(result, "Iterations: " + std::to_string(iterations_));
    
    if (component_name_ == "TPUFeatureExtractor") {
        // Test TPU Feature Extractor performance
        try {
            // Load test image
            cv::Mat image = cv::imread(test_data_path_, cv::IMREAD_GRAYSCALE);
            if (image.empty()) {
                SetFailure(result, "Failed to load test image: " + test_data_path_);
                return;
            }
            
            // Create TPU Feature Extractor
            TPUFeatureExtractor extractor("/path/to/model.tflite", "", 1000, 1.2f, 8);
            
            // Warm-up
            std::vector<cv::KeyPoint> keypoints;
            cv::Mat descriptors;
            extractor(image, cv::Mat(), keypoints, descriptors);
            
            // Measure performance
            std::vector<double> times;
            for (int i = 0; i < iterations_; ++i) {
                auto start = std::chrono::high_resolution_clock::now();
                
                extractor(image, cv::Mat(), keypoints, descriptors);
                
                auto end = std::chrono::high_resolution_clock::now();
                auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
                times.push_back(duration.count() / 1000.0); // Convert to milliseconds
            }
            
            // Calculate statistics
            double sum = std::accumulate(times.begin(), times.end(), 0.0);
            double mean = sum / times.size();
            
            std::sort(times.begin(), times.end());
            double median = times[times.size() / 2];
            double min = times.front();
            double max = times.back();
            
            // Calculate standard deviation
            double sq_sum = std::inner_product(times.begin(), times.end(), times.begin(), 0.0);
            double stdev = std::sqrt(sq_sum / times.size() - mean * mean);
            
            // Log results
            Log(result, "Performance results:");
            Log(result, "  Mean: " + std::to_string(mean) + " ms");
            Log(result, "  Median: " + std::to_string(median) + " ms");
            Log(result, "  Min: " + std::to_string(min) + " ms");
            Log(result, "  Max: " + std::to_string(max) + " ms");
            Log(result, "  StdDev: " + std::to_string(stdev) + " ms");
            Log(result, "  FPS: " + std::to_string(1000.0 / mean));
            
            SetSuccess(result, "Performance test completed successfully");
        } catch (const std::exception& e) {
            SetFailure(result, std::string("Exception: ") + e.what());
        }
    } else if (component_name_ == "VRMotionModel") {
        // Placeholder for VR Motion Model performance test
        Log(result, "VR Motion Model performance test not fully implemented yet");
        SetSuccess(result, "Performance test placeholder passed");
    } else if (component_name_ == "MultiCameraRig") {
        // Placeholder for Multi-Camera Rig performance test
        Log(result, "Multi-Camera Rig performance test not fully implemented yet");
        SetSuccess(result, "Performance test placeholder passed");
    } else {
        SetFailure(result, "Unknown component: " + component_name_);
    }
}

} // namespace ORB_SLAM3
